{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e58b037-94b2-41fa-9f5d-1924b8ca630d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs detected: ['/physical_device:GPU:0']\n",
      "TensorFlow is using the GPU(s).\n",
      "Computation performed on: /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if TensorFlow detects any GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"GPUs detected: {[gpu.name for gpu in gpus]}\")\n",
    "    print(\"TensorFlow is using the GPU(s).\")\n",
    "else:\n",
    "    print(\"No GPUs detected. TensorFlow is running on the CPU.\")\n",
    "\n",
    "# Verify the device used for computation\n",
    "@tf.function\n",
    "def simple_operation():\n",
    "    return tf.matmul([[1.0]], [[1.0]])\n",
    "\n",
    "# Run a simple operation to check the device\n",
    "with tf.device('/GPU:0' if gpus else '/CPU:0'):\n",
    "    result = simple_operation()\n",
    "    print(f\"Computation performed on: {result.device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41f40c36-1503-45f5-a800-17c853169db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d93467f2-0016-4dd2-97bf-c7a8a5d90e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn\n",
    "# print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c772e60d-92e0-485b-b73f-e81ece1bf79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Cropping2D, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a63517d-8eea-4f45-bbb7-526fa7f0a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image dimensions and input shape\n",
    "IMG_HEIGHT, IMG_WIDTH = 224, 224  # Resize images to 224x224\n",
    "INPUT_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 3)  # 3 channels for RGB images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5c8664e-b0dd-458c-aec2-2d1b5d1b2d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained MobileNetV2 model without the top (fully connected) layers\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "537394f2-0d9b-48d0-9281-56eec04981ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Freeze the convolutional layers of MobileNetV2\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e33d534-5c1d-4033-b33d-0de5fbd5185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Sequential CNN model using the pre-trained base model\n",
    "model = Sequential([\n",
    "    # Remove cropping and just use the base model\n",
    "    base_model,\n",
    "    \n",
    "    # Global average pooling to reduce dimensions of feature maps\n",
    "    GlobalAveragePooling2D(),\n",
    "    \n",
    "    # Fully connected layer for learning complex patterns\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),  # Dropout layer to prevent overfitting\n",
    "\n",
    "    # Output layer: 4 neurons for 4 classes, softmax for probabilities\n",
    "    Dense(4, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34e524ab-916a-4b8c-b426-6aad10f1797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),  # Adam optimizer\n",
    "              loss='categorical_crossentropy',  # For multi-class classification\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd8e34bc-67f3-42ac-a00a-01b9c76873d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               163968    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,422,468\n",
      "Trainable params: 164,484\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfe2b3ed-93d8-44be-9d11-2db0011da2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare the data using ImageDataGenerator\n",
    "train_data_dir = \"C:\\\\Users\\\\Vignesh\\\\Desktop\\\\Jupyter\\\\RoadConditionCNN\\\\Traning\"\n",
    "test_data_dir =\"C:\\\\Users\\\\Vignesh\\\\Desktop\\\\Jupyter\\\\RoadConditionCNN\\\\Testing\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b20de78-80fd-41ae-8553-22be181fe1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply data augmentation to training data\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255,  # Normalize pixel values to [0, 1]\n",
    "                                   rotation_range=15,  # Randomly rotate images\n",
    "                                   width_shift_range=0.1,  # Randomly shift images horizontally\n",
    "                                   height_shift_range=0.1,  # Randomly shift images vertically\n",
    "                                   shear_range=0.1,  # Shear transformation\n",
    "                                   zoom_range=0.1,  # Randomly zoom images\n",
    "                                   horizontal_flip=True)  # Flip images horizontally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2129c43f-f72b-4c82-8a85-50e407aad460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For test data, only normalize pixel values\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48e3db0e-b3c0-4f34-bc07-e43ccdf79119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1016 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),  # Resize images\n",
    "    batch_size=16,  # Number of images per batch\n",
    "    class_mode='categorical'  # For multi-class classification\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6766685a-d229-42b9-a2e3-ae019f206a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 256 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load test data\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51039bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "64/64 [==============================] - 22s 335ms/step - loss: 0.1060 - accuracy: 0.9596 - val_loss: 1.6340 - val_accuracy: 0.7148\n",
      "Epoch 2/10\n",
      "64/64 [==============================] - 18s 279ms/step - loss: 0.1066 - accuracy: 0.9626 - val_loss: 0.9577 - val_accuracy: 0.6914\n",
      "Epoch 3/10\n",
      "64/64 [==============================] - 18s 278ms/step - loss: 0.0920 - accuracy: 0.9675 - val_loss: 1.7504 - val_accuracy: 0.7344\n",
      "Epoch 4/10\n",
      "64/64 [==============================] - 18s 285ms/step - loss: 0.0942 - accuracy: 0.9646 - val_loss: 1.3706 - val_accuracy: 0.7266\n",
      "Epoch 5/10\n",
      "64/64 [==============================] - 18s 282ms/step - loss: 0.1040 - accuracy: 0.9656 - val_loss: 1.3184 - val_accuracy: 0.7422\n",
      "Epoch 6/10\n",
      "64/64 [==============================] - 18s 280ms/step - loss: 0.0987 - accuracy: 0.9675 - val_loss: 1.2527 - val_accuracy: 0.7266\n",
      "Epoch 7/10\n",
      "64/64 [==============================] - 18s 282ms/step - loss: 0.0811 - accuracy: 0.9715 - val_loss: 1.1697 - val_accuracy: 0.7227\n",
      "Epoch 8/10\n",
      "64/64 [==============================] - 18s 282ms/step - loss: 0.0720 - accuracy: 0.9675 - val_loss: 1.8388 - val_accuracy: 0.7266\n",
      "Epoch 9/10\n",
      "64/64 [==============================] - 18s 283ms/step - loss: 0.0886 - accuracy: 0.9646 - val_loss: 1.7693 - val_accuracy: 0.7266\n",
      "Epoch 10/10\n",
      "46/64 [====================>.........] - ETA: 4s - loss: 0.0729 - accuracy: 0.9728"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,  # Number of training epochs\n",
    "    validation_data=test_generator  # Use test data for validation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1ea1641-a1ea-4cf6-a593-e31c84eeddba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 121ms/step - loss: 0.8763 - accuracy: 0.6758\n",
      "Test Loss: 0.8763208389282227\n",
      "Test Accuracy: 0.67578125\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10b45e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x1bad072e620>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe9b48e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_generator.class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b7c2ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE THE MODEL\n",
    "\n",
    "# Save the model in HDF5 format\n",
    "model.save('road_condition_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c519933-6819-4496-b26d-b4d6259c82e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (py310_env)",
   "language": "python",
   "name": "py310_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
